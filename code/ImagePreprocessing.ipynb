{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_MISSION = 2\n",
    "\n",
    "RESIZE_SCALE = 0.1\n",
    "\n",
    "REFERENCE_CROP_L = 30\n",
    "REFERENCE_CROP_R = 145\n",
    "REFERENCE_CROP_T = 80\n",
    "REFERENCE_CROP_B = 90\n",
    "\n",
    "REGION_NAMES = ['GRASS', 'SIDEWALK', 'BUILDING', 'GRAVEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mission_file_path(mission_number):\n",
    "    return '..\\\\missions\\\\mission_' + str(mission_number) + '\\\\mission_' + str(mission_number) + '_'\n",
    "\n",
    "def get_mission_segmentation_file_path(mission_number):\n",
    "    return '..\\\\missions\\\\mission_' + str(mission_number) + '_segmentation\\\\mission_' + str(mission_number) + '_'\n",
    "\n",
    "def plot_images(image_list, title_list=[], grid='off'):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(image_list), figsize=(10*len(image_list), 10*1))\n",
    "    if len(image_list) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(cv2.cvtColor(image_list[i], cv2.COLOR_BGR2RGB))\n",
    "        if len(title_list) > 0:\n",
    "            ax.set_title(title_list[i])\n",
    "        ax.axis(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_masks(mission_number, is_mission_image, file_name=''):\n",
    "    if is_mission_image:\n",
    "        result = cv2.imread(get_mission_segmentation_file_path(mission_number) + 'bordered.png').astype(np.uint8)\n",
    "        result = cv2.resize(result, (0,0), fx=RESIZE_SCALE, fy=RESIZE_SCALE)\n",
    "    else:\n",
    "        result = dict()\n",
    "        for name in REGION_NAMES:\n",
    "            if mission_number == REFERENCE_MISSION:\n",
    "                mask = np.load(get_mission_segmentation_file_path(REFERENCE_MISSION) + file_name + '_%s.npy' % (name)).astype(np.uint8)*255\n",
    "                mask = cv2.resize(mask, (0,0), fx=RESIZE_SCALE, fy=RESIZE_SCALE)\n",
    "            else:\n",
    "                mask = np.load(get_mission_file_path(REFERENCE_MISSION) + file_name + '_%s.npy' % (name)) # no .astype(np.uint8)*255\n",
    "            result[name] = mask\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_aligned_global_image(mission_number):\n",
    "    mission = np.load(get_mission_file_path(mission_number) + 'aligned_image.npy')\n",
    "    return mission\n",
    "\n",
    "def calculate_masked_images(mission_image, masks):\n",
    "    images = dict()\n",
    "    for name in REGION_NAMES:\n",
    "        image = cv2.bitwise_and(mission_image, mission_image, mask=masks[name])\n",
    "        images[name] = image.astype(np.uint8)\n",
    "\n",
    "    return images\n",
    "\n",
    "def save_images_and_masks(mission_number, images, is_mission_image, filename):\n",
    "    if is_mission_image:\n",
    "        np.save(get_mission_file_path(mission_number) + filename + '.npy', images)\n",
    "    else:\n",
    "        for name in REGION_NAMES:\n",
    "            np.save(get_mission_file_path(mission_number) + filename + '_%s.npy' % (name), images[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectAndDescribe(image, method):\n",
    "    # compute key points and feature descriptors\n",
    "        \n",
    "    if method == 'sift':\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "    elif method == 'surf':\n",
    "        descriptor = cv2.xfeatures2d.SURF_create()\n",
    "    elif method == 'brisk':\n",
    "        descriptor = cv2.BRISK_create()\n",
    "    elif method == 'orb':\n",
    "        descriptor = cv2.ORB_create()\n",
    "        \n",
    "    # get keypoints and descriptors\n",
    "    (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "    \n",
    "    return (kps, features)\n",
    "\n",
    "def createMatcher(method, crossCheck):    \n",
    "    if method == 'sift' or method == 'surf':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=crossCheck)\n",
    "    elif method == 'orb' or method == 'brisk':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=crossCheck)\n",
    "    return bf\n",
    "\n",
    "def matchKeyPointsBF(features_global, features_add, method):\n",
    "    bf = createMatcher(method, crossCheck=True) # cross check f1 closest to f2 and f2 closest to f1\n",
    "    \n",
    "    # Match descriptors.\n",
    "    best_matches = bf.match(features_global, features_add)\n",
    "    \n",
    "    # Sort the features in order of distance.\n",
    "    # The points with small distance (more similarity) are ordered first in the vector\n",
    "    rawMatches = sorted(best_matches, key = lambda x:x.distance)\n",
    "    return rawMatches\n",
    "\n",
    "def getHomography(kp_add, kp_global, features_add, features_global, matches, reprojThresh):\n",
    "    # convert the keypoints to numpy arrays\n",
    "    kp_add = np.float32([kp.pt for kp in kp_add])\n",
    "    kp_global = np.float32([kp.pt for kp in kp_global])\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "\n",
    "        # construct the two sets of points\n",
    "        pts_add = np.float32([kp_add[m.queryIdx] for m in matches])\n",
    "        pts_global = np.float32([kp_global[m.trainIdx] for m in matches])\n",
    "        \n",
    "        # estimate the homography between the sets of points\n",
    "        (H, status) = cv2.findHomography(pts_add, pts_global, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "        return (matches, H, status)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def align_to_reference_helper(im1, im2):\n",
    "    feature_extractor = 'brisk'\n",
    "\n",
    "    add_img_gray = cv2.cvtColor(im1, cv2.COLOR_RGB2GRAY)\n",
    "    global_img_gray = cv2.cvtColor(im2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    kp_global, features_global = detectAndDescribe(global_img_gray, method=feature_extractor)\n",
    "    kp_add, features_add = detectAndDescribe(add_img_gray, method=feature_extractor)\n",
    "\n",
    "    matches = matchKeyPointsBF(features_add, features_global, method=feature_extractor)\n",
    "\n",
    "    M = getHomography(kp_add, kp_global, features_add, features_global, matches, reprojThresh=4)\n",
    "    if M is None:\n",
    "        print(\"Error!\")\n",
    "    (matches, H, status) = M\n",
    "    \n",
    "    # Use homography\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, H, (width, height))\n",
    "\n",
    "    return im1Reg, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_reference(mission_number, images, is_mission_image):\n",
    "    \n",
    "    if mission_number == REFERENCE_MISSION:        \n",
    "        if is_mission_image:\n",
    "            h_ref, w_ref, _ = images.shape\n",
    "        else:\n",
    "            h_ref, w_ref = images[REGION_NAMES[0]].shape\n",
    "            \n",
    "        aligned_images = copy.deepcopy(images)\n",
    "    else:\n",
    "        # perform alignment\n",
    "        reference_mission = np.load(get_mission_file_path(REFERENCE_MISSION) + 'aligned_image.npy')\n",
    "        h_ref, w_ref, c_ref = reference_mission.shape\n",
    "        if is_mission_image:\n",
    "            tobealigned_mission = images\n",
    "            aligned_mission, H = align_to_reference_helper(tobealigned_mission, reference_mission)\n",
    "            \n",
    "            np.save(get_mission_file_path(mission_number) + 'H_from_mission_' + str(REFERENCE_MISSION) + '.npy', H)\n",
    "            \n",
    "            aligned_images = aligned_mission\n",
    "        else:\n",
    "            H = np.load(get_mission_file_path(mission_number) + 'H_from_mission_' + str(REFERENCE_MISSION) + '.npy')\n",
    "            # must be same shape, which it is. use same H\n",
    "            \n",
    "            aligned_images = dict()\n",
    "            for name in REGION_NAMES:\n",
    "                aligned_image = cv2.warpPerspective(images[name], H, (w_ref, h_ref))\n",
    "                aligned_images[name] = aligned_image\n",
    "    \n",
    "    if mission_number == REFERENCE_MISSION:\n",
    "        if is_mission_image: # for global image\n",
    "            result = copy.deepcopy(aligned_images)[REFERENCE_CROP_T:h_ref-REFERENCE_CROP_B, REFERENCE_CROP_L:w_ref-REFERENCE_CROP_R, :]\n",
    "        else: # for region and sample masks\n",
    "            result = dict()\n",
    "            for k, v in aligned_images.items():\n",
    "                result[k] = copy.deepcopy(v)[REFERENCE_CROP_T:h_ref-REFERENCE_CROP_B, REFERENCE_CROP_L:w_ref-REFERENCE_CROP_R]\n",
    "        return result\n",
    "    else:\n",
    "        return aligned_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_channels(I):\n",
    "    I = color.rgb2lab(I)\n",
    "    I = I.astype(np.float32)\n",
    "    I1, I2, I3 = (I[:, :, 0], I[:, :, 1], I[:, :, 2])\n",
    "    I1 /= 2.55\n",
    "    I2 -= 128.0\n",
    "    I3 -= 128.0\n",
    "    return I1, I2, I3\n",
    "\n",
    "def get_mean_and_std(channels):\n",
    "    mean = (np.mean(channels[0]), np.mean(channels[1]), np.mean(channels[2]))\n",
    "    std = (np.std(channels[0]), np.std(channels[1]), np.std(channels[2]))\n",
    "    return mean, std\n",
    "\n",
    "def merge_channels(I1, I2, I3):\n",
    "    I1 *= 2.55\n",
    "    I2 += 128.0\n",
    "    I3 += 128.0\n",
    "    \n",
    "    I = np.stack((I1, I2, I3), axis=2)\n",
    "    return color.lab2rgb(I)\n",
    "\n",
    "#fit source to target\n",
    "def single_reinhard(target, source):\n",
    "    target_channels = separate_channels(target)\n",
    "    source_channels = separate_channels(source)\n",
    "    \n",
    "    source_mean, source_std = get_mean_and_std(source_channels)\n",
    "    target_mean, target_std = get_mean_and_std(target_channels)\n",
    "    \n",
    "    modified1 = ((source_channels[0] - source_mean[0]) * (target_std[0] / source_std[0])) + target_mean[0]\n",
    "    modified2 = ((source_channels[1] - source_mean[1]) * (target_std[1] / source_std[1])) + target_mean[1]\n",
    "    modified3 = ((source_channels[2] - source_mean[2]) * (target_std[2] / source_std[2])) + target_mean[2]\n",
    "    \n",
    "    return merge_channels(modified1, modified2, modified3)*255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_image_preprocessor(mission_number, save_results=False, display_results=True):\n",
    "    print('Preprocessing Mission:', mission_number)\n",
    "    \n",
    "    if not os.path.isdir('..\\\\missions\\\\mission_' + str(mission_number)):\n",
    "        os.mkdir('..\\\\missions\\\\mission_' + str(mission_number))\n",
    "    \n",
    "    # ----------------------------------------\n",
    "\n",
    "    try:\n",
    "        mission_image = load_images_and_masks(mission_number, is_mission_image=True, file_name='')\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    if mission_number == REFERENCE_MISSION:\n",
    "        regions_mask = load_images_and_masks(mission_number, is_mission_image=False, file_name='region_mask')\n",
    "        samples_mask = load_images_and_masks(mission_number, is_mission_image=False, file_name='sample_mask')\n",
    "        \n",
    "    # ----------------------------------------\n",
    "    \n",
    "    aligned_mission_image = align_to_reference(mission_number, mission_image, is_mission_image=True) # need to run this first to get homography matrix\n",
    "    if mission_number == REFERENCE_MISSION:\n",
    "        aligned_regions_mask = align_to_reference(mission_number, regions_mask, is_mission_image=False)\n",
    "        aligned_samples_mask = align_to_reference(mission_number, samples_mask, is_mission_image=False)\n",
    "    else: # load prealigned masks\n",
    "        aligned_regions_mask = load_images_and_masks(mission_number, is_mission_image=False, file_name='aligned_region_mask')\n",
    "        aligned_samples_mask = load_images_and_masks(mission_number, is_mission_image=False, file_name='aligned_sample_mask')\n",
    "        \n",
    "    # ----------------------------------------\n",
    "        \n",
    "    aligned_regions_image = calculate_masked_images(aligned_mission_image, aligned_regions_mask)\n",
    "    aligned_samples_image = calculate_masked_images(aligned_mission_image, aligned_samples_mask)\n",
    "\n",
    "    # ----------------------------------------\n",
    "\n",
    "    if mission_number == REFERENCE_MISSION:\n",
    "        target = copy.deepcopy(aligned_mission_image)\n",
    "    else:\n",
    "        target = get_aligned_global_image(REFERENCE_MISSION)\n",
    "\n",
    "    normalized_mission_image = single_reinhard(target, aligned_mission_image).astype(np.uint8)\n",
    "    \n",
    "    normalized_regions_image = calculate_masked_images(normalized_mission_image, aligned_regions_mask)\n",
    "    normalized_samples_image = calculate_masked_images(normalized_mission_image, aligned_samples_mask)\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    \n",
    "    if save_results:\n",
    "        save_images_and_masks(mission_number, aligned_mission_image, is_mission_image=True, filename='aligned_image')\n",
    "        save_images_and_masks(mission_number, normalized_mission_image, is_mission_image=True, filename='normalized_image')\n",
    "\n",
    "        save_images_and_masks(mission_number, aligned_regions_image, is_mission_image=False, filename='aligned_region_image')\n",
    "        save_images_and_masks(mission_number, aligned_samples_image, is_mission_image=False, filename='aligned_sample_image')\n",
    "\n",
    "        save_images_and_masks(mission_number, normalized_regions_image, is_mission_image=False, filename='normalized_region_image')\n",
    "        save_images_and_masks(mission_number, normalized_samples_image, is_mission_image=False, filename='normalized_sample_image')\n",
    "\n",
    "        if mission_number == REFERENCE_MISSION:\n",
    "            save_images_and_masks(mission_number, aligned_regions_mask, is_mission_image=False, filename='aligned_region_mask')\n",
    "            save_images_and_masks(mission_number, aligned_samples_mask, is_mission_image=False, filename='aligned_sample_mask')\n",
    "    \n",
    "    if display_results:\n",
    "        plot_images([mission_image, aligned_mission_image], ['mission_image', 'aligned_mission_image'])\n",
    "        \n",
    "        plot_images([cv2.bitwise_or(cv2.bitwise_or(aligned_regions_mask[REGION_NAMES[0]], aligned_regions_mask[REGION_NAMES[1]]), cv2.bitwise_or(aligned_regions_mask[REGION_NAMES[2]], aligned_regions_mask[REGION_NAMES[3]]))], ['total aligned mask'], grid='on')\n",
    "        \n",
    "        if mission_number == REFERENCE_MISSION:\n",
    "            plot_images(list(regions_mask.values()), REGION_NAMES)\n",
    "        plot_images(list(aligned_regions_mask.values()), REGION_NAMES)\n",
    "\n",
    "        if mission_number == REFERENCE_MISSION:\n",
    "            plot_images(list(samples_mask.values()), REGION_NAMES)\n",
    "        plot_images(list(aligned_samples_mask.values()), REGION_NAMES)\n",
    "        \n",
    "        plot_images(list(aligned_regions_image.values()), REGION_NAMES)\n",
    "        plot_images(list(aligned_samples_image.values()), REGION_NAMES)\n",
    "\n",
    "        plot_images([target, aligned_mission_image, normalized_mission_image], ['target', 'aligned_mission_image', 'normalized_mission_image'])\n",
    "        plot_images(list(normalized_regions_image.values()), REGION_NAMES)\n",
    "        plot_images(list(normalized_samples_image.values()), REGION_NAMES)\n",
    "        \n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
